---
title: Runn LLM locally
description: Runn LLM locally
date: '2024-01-11'
draft: false
slug: /pensieve/llms
tags: ["LLM", "AI", "ML"]
tech:
  - Python
  - LLM
  - AI
  - ML
  - GenAI
  - RAG
  - Streamlit
company: 'Individual'
github: 'https://github.com/fedihamdi/'
external: 'https://medium.com/@fedihamdi.jr'
showInProjects: true
---



[Full article](https://medium.com/@fedihamdi.jr/run-llm-locally-a-step-by-step-guide-02fc69a12c72) | 4 min read | 

<img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*McJpkhd8MCbX7x5wh9Qi2Q.gif" alt="Fedi HAMDI" height="200" width="100"/>


# Introduction üåü

In this guide, we‚Äôll walk you through the process of creating your own personal assistant using open-source Large Language Models (LLMs). The best part? It won‚Äôt cost you a penny. We‚Äôll leverage tools like GPT4All and llama-cpp-python to set up and run LLMs on your local laptop for enhanced privacy and cost-effectiveness.

# Set Up Your Environment üõ†Ô∏è

First things first, let‚Äôs set up the environment by installing the necessary dependencies. Open your Jupyter notebook and execute the following commands:

```python
!pip install --upgrade llama-cpp-python langchain gpt4all llama-index sentence-transformers
```

# Run LLM Locally üè°: 1st attempt

[Full article](https://medium.com/@fedihamdi.jr/run-llm-locally-a-step-by-step-guide-02fc69a12c72)